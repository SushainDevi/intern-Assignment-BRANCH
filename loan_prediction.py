# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/170GRnz3z3QUHjj270oKDjsxzE1TR8vSi
"""

import pandas as pd
from sqlalchemy import create_engine

db_params = {
    'host': 'branchhomeworkdb.cv8nj4hg6yra.ap-south-1.rds.amazonaws.com',
    'port': '5432',
    'database': 'branchdsprojectgps',
    'user': 'datascientist',
    'password': '47eyYBLT0laW5j9U24Uuy8gLcrN'
}

engine = create_engine(f"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}")

loan_outcomes = pd.read_sql("SELECT * FROM loan_outcomes", engine)
gps_fixes = pd.read_sql("SELECT * FROM gps_fixes", engine)
user_attributes = pd.read_sql("SELECT * FROM user_attributes", engine)

print(loan_outcomes.head())
print(gps_fixes.head())
print(user_attributes.head())

#NULL VALUE check

print(loan_outcomes.info())
print(gps_fixes.describe())
print(user_attributes.isnull().sum())

# merging the database
merged_data = loan_outcomes.merge(user_attributes, on='user_id', how='left')
merged_data = merged_data.merge(gps_fixes, on='user_id', how='left')
print(merged_data.head())

# Visuals
import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=loan_outcomes, x='loan_outcome')
plt.title("Loan Outcome Distribution")
plt.show()

# Feature Engineering
# 1. LOAN outcomes

merged_data['loan_outcome'] = merged_data['loan_outcome'].map({'yes': 1, 'no': 0})
print(merged_data.head())

#2. GPS data
# Approach - Simplified Aggregations with Bounding Box

import pandas as pd


gps_counts = gps_fixes.groupby('user_id').size().reset_index(name='gps_fix_count')

gps_stats = gps_fixes.groupby('user_id').agg(
    mean_latitude=('latitude', 'mean'),
    mean_longitude=('longitude', 'mean'),
    var_latitude=('latitude', 'var'),
    var_longitude=('longitude', 'var')
).reset_index()

gps_bounding_box = gps_fixes.groupby('user_id').agg(
    lat_range=('latitude', lambda x: x.max() - x.min()),
    lon_range=('longitude', lambda x: x.max() - x.min())
).reset_index()

gps_bounding_box['movement_radius_approx'] = (
    gps_bounding_box['lat_range'] + gps_bounding_box['lon_range']
) / 2

gps_features = gps_counts.merge(gps_stats, on='user_id', how='left')
gps_features = gps_features.merge(gps_bounding_box[['user_id', 'movement_radius_approx']], on='user_id', how='left')

gps_fixes['hour'] = pd.to_datetime(gps_fixes['gps_fix_at']).dt.hour
hourly_activity = gps_fixes.groupby(['user_id', 'hour']).size().unstack(fill_value=0)
hourly_activity['peak_hour'] = hourly_activity.idxmax(axis=1)
gps_features = gps_features.merge(hourly_activity[['peak_hour']], on='user_id', how='left')

# Display the final GPS features
print(gps_features.head())

# missing values

gps_features.fillna({'var_latitude': 0, 'var_longitude': 0}, inplace=True)
print(gps_features.isnull().sum())

# merging the feature with loan_outcomes

merged_data = loan_outcomes.merge(gps_features, on='user_id', how='left')
merged_data['loan_outcome'] = pd.to_numeric(merged_data['loan_outcome'], errors='coerce')

print(merged_data.corr()['loan_outcome'])

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_features = scaler.fit_transform(gps_features[['gps_fix_count', 'movement_radius_approx']])
gps_features[['gps_fix_count_scaled', 'movement_radius_approx_scaled']] = scaled_features
print(gps_features.head())

main_dataset = loan_outcomes.merge(user_attributes, on='user_id', how='left')

main_dataset = main_dataset.merge(gps_features, on='user_id', how='left')


main_dataset.fillna({
    'gps_fix_count': 0,
    'mean_latitude': 0,
    'mean_longitude': 0,
    'var_latitude': 0,
    'var_longitude': 0,
    'movement_radius_approx': 0,
    'peak_hour': -1
}, inplace=True)

print(main_dataset.head())

main_dataset.to_csv('loan_prediction_dataset.csv', index=False)

main_dataset['loan_outcome'] = main_dataset['loan_outcome'].map({'repaid': 1, 'defaulted': 0})

print(main_dataset.corr()['loan_outcome'])

# Features Selected for Modeling:
#1.cash_incoming_30days
#2.gps_fix_count_scaled
#3.movement_radius_approx_scaled
#4.age
#5.var_longitude

# Data Preparing of model

from sklearn.model_selection import train_test_split

features = [
    'cash_incoming_30days',
    'gps_fix_count_scaled',
    'movement_radius_approx_scaled',
    'age',
    'var_longitude'
]
target = 'loan_outcome'

X = main_dataset[features]
y = main_dataset[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Check split sizes
print("Training set size:", X_train.shape)
print("Testing set size:", X_test.shape)

import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

gps_imputer = SimpleImputer(strategy='constant', fill_value=0)
numeric_imputer = SimpleImputer(strategy='median')

gps_features = ['gps_fix_count_scaled', 'movement_radius_approx_scaled']
other_features = ['cash_incoming_30days', 'age', 'var_longitude']

X_gps = X[gps_features]
X_gps_imputed = gps_imputer.fit_transform(X_gps)

X_other = X[other_features]
X_other_imputed = numeric_imputer.fit_transform(X_other)

X_imputed = np.hstack([X_other_imputed, X_gps_imputed])

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=5,
    min_samples_split=5,
    class_weight='balanced',
    random_state=42
)

cv_scores = cross_val_score(rf, X_scaled, y, cv=5, scoring='roc_auc')
print("\nCross-validation ROC-AUC scores:", cv_scores)
print("Mean ROC-AUC:", cv_scores.mean())
print("Standard deviation:", cv_scores.std())

rf.fit(X_scaled, y)

feature_importance = pd.DataFrame({
    'Feature': features,
    'Importance': rf.feature_importances_
})
print("\nRandom Forest Feature Importance:")
print(feature_importance.sort_values('Importance', ascending=False))

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf = RandomForestClassifier(class_weight='balanced', random_state=42)

grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,
    scoring='roc_auc',
    n_jobs=-1
)

grid_search.fit(X_scaled, y)

print("Best parameters:", grid_search.best_params_)
print("Best ROC-AUC score:", grid_search.best_score_)

final_model = RandomForestClassifier(
    **grid_search.best_params_,
    class_weight='balanced',
    random_state=42
)
final_model.fit(X_scaled, y)

final_importance = pd.DataFrame({
    'Feature': features,
    'Importance': final_model.feature_importances_
})
print("\nFinal Model Feature Importance:")
print(final_importance.sort_values('Importance', ascending=False))

# Save the final model
import pickle
model_pipeline = {
    'gps_imputer': gps_imputer,
    'numeric_imputer': numeric_imputer,
    'scaler': scaler,
    'model': final_model,
    'features': features,
    'gps_features': gps_features,
    'other_features': other_features
}

with open('loan_default_model.pkl', 'wb') as f:
    pickle.dump(model_pipeline, f)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report

y_pred = final_model.predict(X_scaled)
y_pred_proba = final_model.predict_proba(X_scaled)[:, 1]

fpr, tpr, thresholds = roc_curve(y, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

cm = confusion_matrix(y, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

report = classification_report(y, y_pred)
print("Classification Report:\n", report)

plt.figure(figsize=(10, 6))
feature_importance = pd.Series(final_model.feature_importances_, index=features)
feature_importance.nlargest(10).plot(kind='barh')
plt.title('Top 10 Feature Importances')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.show()